{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " class ReplayMemory:\n",
    "    #rotating buffer of size N\n",
    "    def __init__(self,N,batch_size=500):\n",
    "        self.memory = []\n",
    "        self.size = N\n",
    "        self.batch_size =batch_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        self.memory.append(experience)\n",
    "        if(len(self.memory) > self.size):\n",
    "            del self.memory[0]\n",
    "    \n",
    "    def replay(self):    \n",
    "        \n",
    "        # we want to keep some information about direction though \n",
    "        # so we will give 3 frames at a time\n",
    "        \n",
    "        buffer_size = len(self.memory)\n",
    "        output = np.array(self.memory)\n",
    "        \n",
    "        if(buffer_size < self.batch_size):\n",
    "            return []\n",
    "        \n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                size = self.batch_size,\n",
    "                                replace = False)\n",
    "        return output[index]\n",
    "\n",
    "#Define what our experience looks like\n",
    "#[state,action,reward,next_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_actions = 4\n",
    "# DQN network from this tutorial \n",
    "# https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288\n",
    "# We will probably tweak this but our main interesting part is training this model\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # 4 input image channel, 32 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(5, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(21904, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, number_of_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut off the infromation on the top and grayscale\n",
    "def format_frame(frame):\n",
    "    frame =np.mean(frame,axis=2)\n",
    "    frame = frame[35:-15]\n",
    "    return frame\n",
    "\n",
    "def get_most_likely_action(action_confidences):\n",
    "    #returns the index of the most likely action\n",
    "    return np.argmax(action_confidences)\n",
    "\n",
    "def to_onehot(index,size):\n",
    "    #makes a onehot array of size size\n",
    "    # with the index index 1 and all others 0\n",
    "    onehot = torch.zeros(size)\n",
    "    onehot[index] = 1\n",
    "    return onehot\n",
    "\n",
    "def format_frames(stacked_frames):\n",
    "    # turn a list of numpy arrays into \n",
    "    # a torch tensor\n",
    "    torch_frames = [torch.from_numpy(n).float() for n in stacked_frames]\n",
    "    #now stack them into one big tensor\n",
    "    output_tensor = torch.stack(torch_frames)\n",
    "    output_tensor = torch.reshape(output_tensor,(1,len(torch_frames),160,160))\n",
    "    return output_tensor\n",
    "\n",
    "def get_best_action(model,stacked_frames):\n",
    "    #get our best action from our learner\n",
    "    #print(\"state given:\",state)\n",
    "    frames_tensor = format_frames(stacked_frames)\n",
    "    \n",
    "    action = model.forward(frames_tensor).detach().numpy()[0]\n",
    "    #action = int(action)\n",
    "    #print(\"State:\",state,\"Action:\",action)\n",
    "    action = np.array(action)\n",
    "    action = get_most_likely_action(action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_actions = 4\n",
    "\n",
    "def learn_from_data(model,target,data,optim):\n",
    "    for experience in data:\n",
    "        #compute the loss from\n",
    "        state,action,reward,next_state = experience\n",
    "        #make the action match what the network outputs\n",
    "        \n",
    "        #belman equation\n",
    "        state = format_frames(state)\n",
    "        next_state = format_frames(next_state)\n",
    "        \n",
    "        chosen_action_based_on_reward = model.forward(state)\n",
    "        \n",
    "        expected_reward = target.forward(next_state).detach_()\n",
    "        \n",
    "        reward_tensor = torch.zeros(number_of_actions)\n",
    "        reward_tensor[action] = reward\n",
    "        \n",
    "        #reward_tensor.float()\n",
    "        #print(reward_tensor)\n",
    "        \n",
    "        expected_reward += reward_tensor\n",
    "        \n",
    "        loss = F.l1_loss(chosen_action_based_on_reward,expected_reward)\n",
    "        #we want the chosen_action based on reward to match \n",
    "        #the reward of being in the next state and the reward given\n",
    "        \n",
    "        #print(reward)\n",
    "        \n",
    "        # must zero gradients before backprop\n",
    "        # for pytorch\n",
    "        optim.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(exploration_rate,state,model):\n",
    "    uniform_random_variable= random.uniform(0,1)\n",
    "        \n",
    "    if(uniform_random_variable > exploration_rate):\n",
    "        \n",
    "        #state = torch.tensor([[state]])\n",
    "        #state=state.float()\n",
    "\n",
    "        action = get_best_action(model,state)\n",
    "        \n",
    "    else:\n",
    "        #other wise explore randomly\n",
    "        action = env.action_space.sample()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(model,target):\n",
    "    target.load_state_dict(model.state_dict())\n",
    "    #print(\"model:\",model.state_dict())\n",
    "    #print(\"target:\",target.state_dict())\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training loop\n",
    "# Currently we do not have a target network but we could do that\n",
    "num_episodes = 1000000\n",
    "training_episodes = 10\n",
    "target_episodes = 15\n",
    "# network_update_epochs = 100 #use this if using a target network\n",
    "game_length = 10000\n",
    "\n",
    "# exploration rate, we want our network to explore \n",
    "# sometimes but not all the time, to do this\n",
    "# we use a decaying exploration rate\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.01\n",
    "# this bit of code will determine the decay\n",
    "# exploration_rate = min_exploration_rate + \\\n",
    "#        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=21904, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "replay_memory = ReplayMemory(10000)\n",
    "dqn = DQN()#96,96)\n",
    "target = DQN()\n",
    "optimizer = optim.SGD(dqn.parameters(),lr=.01)\n",
    "print(dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = update_target(dqn,target)\n",
    "\n",
    "def play_game(dqn,replay_memory,env,bounding_reward = True,show=False):\n",
    "    time.sleep(.1)\n",
    "    frame= env.reset()\n",
    "    frame = format_frame(frame)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    tko_timer = 0\n",
    "    game = []\n",
    "    \n",
    "    action_frequency = 5\n",
    "    \n",
    "    stacked_frames = []\n",
    "    previous_frames = []\n",
    "    stacked_reward = 0\n",
    "    #stacked_frames.append(frame)\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    \n",
    "    for step in range(game_length):\n",
    "        if(show==True):\n",
    "            env.render()\n",
    "        #only make a new desision every 5 frames\n",
    "        \n",
    "        frame, reward, done, info = env.step(action)\n",
    "        \n",
    "        \n",
    "        frame = format_frame(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        #env.render() we could render to show ourseleves\n",
    "        if(step % action_frequency==0 and step != 0):\n",
    "            action = select_action(exploration_rate,stacked_frames,dqn)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if(reward < 0 and bounding_reward):\n",
    "            reward = 0\n",
    "        \n",
    "        stacked_reward += reward\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(step % action_frequency==0 and step > action_frequency):\n",
    "            experience= [previous_frames,action,stacked_reward,stacked_frames]\n",
    "            replay_memory.add(experience)\n",
    "        \n",
    "        if(step % action_frequency==0):\n",
    "            previous_frames=stacked_frames\n",
    "            stacked_frames = []\n",
    "            stacked_reward = 0\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "        \n",
    "        \n",
    "        #tracking how far we are getting\n",
    "        episode_reward +=reward\n",
    "        \n",
    "        if(done):\n",
    "            # if we haven't gotten a positive reward \n",
    "            # in the last 20 steps \n",
    "            # or the game is over: stop\n",
    "            break\n",
    "    return episode_reward\n",
    "    \n",
    "def show_progress(rewards):\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    print(\"exploration_rate:\",exploration_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration_rate: 0.9057890438555999\n",
      "Training on Experience\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-381105f18fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtraining_episodes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on Experience\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtarget_episodes\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1433a30ce2e2>\u001b[0m in \u001b[0;36mlearn_from_data\u001b[0;34m(model, target, data, optim)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mchosen_action_based_on_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mexpected_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-35d94f10a15a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# If the size is a square you can only specify a single number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for episode in range(num_episodes):\n",
    "    print(\"Episode:\",episode)\n",
    "    \n",
    "    #the play_game will update replay_memory to include the game\n",
    "    episode_reward = play_game(dqn,replay_memory,env,bounding_reward = False,show=(episode%20==0))\n",
    "    \n",
    "    \n",
    "    #end of episode variable updating\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
    "    \n",
    "    rewards.append(episode_reward)\n",
    "    \n",
    "    show_progress(rewards)\n",
    "    \n",
    "    if(episode % training_episodes == 0 and episode != 0):\n",
    "        print(\"Training on Experience\")\n",
    "        dqn = learn_from_data(dqn,target,replay_memory.replay(),optimizer)\n",
    "    \n",
    "    if(episode%target_episodes ==0):\n",
    "        print(\"updating the target network\")\n",
    "        target = update_target(dqn,target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
