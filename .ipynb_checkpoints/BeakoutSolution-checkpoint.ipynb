{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " class ReplayMemory:\n",
    "    #rotating buffer of size N\n",
    "    def __init__(self,N,batch_size=5000):\n",
    "        self.memory = []\n",
    "        self.size = N\n",
    "        self.batch_size =batch_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        self.memory.append(experience)\n",
    "        if(len(self.memory) > self.size):\n",
    "            del self.memory[0]\n",
    "    \n",
    "    def replay(self):    \n",
    "        #if(len(self.memory) < self.batch_size):\n",
    "        #    return []\n",
    "        #relay everything stored in small minibatches \n",
    "        # (currently of lenght 1)\n",
    "        # in a random order to reduce correlation\n",
    "        \n",
    "        # we want to keep some information about direction though \n",
    "        # so we will give 3 frames at a time\n",
    "        output = np.array(self.memory)\n",
    "        np.random.shuffle(output)\n",
    "        return output[:self.batch_size]\n",
    "\n",
    "#Define what our experience looks like\n",
    "#[state,action,reward,next_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN network from this tutorial \n",
    "# https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288\n",
    "# We will probably tweak this but our main interesting part is training this model\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(24864, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(type(x) != torch.Tensor):\n",
    "            x = torch.Tensor([[x]])\n",
    "            x = x.float()\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut off the infromation on the top and grayscale\n",
    "def format_frame(frame):\n",
    "    frame =np.mean(frame,axis=2)\n",
    "    frame = frame[15:-15]\n",
    "    return frame\n",
    "\n",
    "def get_most_likely_action(action_confidences):\n",
    "    #returns the index of the most likely action\n",
    "    return np.argmax(action_confidences)\n",
    "\n",
    "def to_onehot(index,size):\n",
    "    #makes a onehot array of size size\n",
    "    # with the index index 1 and all others 0\n",
    "    onehot = np.zeros(size)\n",
    "    onehot[index] = 1\n",
    "    return onehot\n",
    "\n",
    "def get_best_action(model,state):\n",
    "    #get our best action from our learner\n",
    "    #print(\"state given:\",state)\n",
    "    action = model.forward(state).detach().numpy()[0]\n",
    "    #action = int(action)\n",
    "    #print(\"State:\",state,\"Action:\",action)\n",
    "    action =  np.array(action)\n",
    "    action = get_most_likely_action(action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_actions =4\n",
    "\n",
    "def learn_from_data(model,target,data,optim):\n",
    "    for experience in data:\n",
    "        #compute the loss from\n",
    "        state,action,reward,next_state = experience\n",
    "        \n",
    "        #make the action match what the network outputs\n",
    "        action = to_onehot(action,number_of_actions)\n",
    "        \n",
    "        #belman equation\n",
    "        \n",
    "        chosen_action_based_on_reward = model.forward(state)\n",
    "        \n",
    "        expected_reward = reward + target.forward(next_state).detach_()\n",
    "        \n",
    "        loss = F.l1_loss(chosen_action_based_on_reward,expected_reward)\n",
    "        #we want the chosen_action based on reward to match \n",
    "        #the reward of being in the next state and the reward given\n",
    "        \n",
    "        #print(reward)\n",
    "        \n",
    "        # must zero gradients before backprop\n",
    "        # for pytorch\n",
    "        optim.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(exploration_rate,state,model):\n",
    "    uniform_random_variable= random.uniform(0,1)\n",
    "        \n",
    "    if(uniform_random_variable > exploration_rate):\n",
    "        \n",
    "        #state = torch.tensor([[state]])\n",
    "        #state=state.float()\n",
    "\n",
    "        action = get_best_action(model,state)\n",
    "        \n",
    "    else:\n",
    "        #other wise explore randomly\n",
    "        action = env.action_space.sample()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(model,target):\n",
    "    target.load_state_dict(model.state_dict())\n",
    "    #print(\"model:\",model.state_dict())\n",
    "    #print(\"target:\",target.state_dict())\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training loop\n",
    "# Currently we do not have a target network but we could do that\n",
    "num_episodes = 1000000\n",
    "training_episodes = 2\n",
    "target_episodes = 15\n",
    "# network_update_epochs = 100 #use this if using a target network\n",
    "game_length = 10000\n",
    "\n",
    "# exploration rate, we want our network to explore \n",
    "# sometimes but not all the time, to do this\n",
    "# we use a decaying exploration rate\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.01\n",
    "# this bit of code will determine the decay\n",
    "# exploration_rate = min_exploration_rate + \\\n",
    "#        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=24864, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "replay_memory = ReplayMemory(100000)\n",
    "dqn = DQN()#96,96)\n",
    "target = DQN()\n",
    "optimizer = optim.SGD(dqn.parameters(),lr=.01)\n",
    "print(dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = update_target(dqn,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration_rate: 0.9803966865736877\n",
      "Training on Experience\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'onehotf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d050296eb9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtraining_episodes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on Experience\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtarget_episodes\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"updating the target network\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f73f3c662fce>\u001b[0m in \u001b[0;36mlearn_from_data\u001b[0;34m(model, target, data, optim)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#make the action match what the network outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#belman equation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5460f6a45fdd>\u001b[0m in \u001b[0;36mto_onehot\u001b[0;34m(index, size)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0monehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0monehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0monehotf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_best_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'onehotf' is not defined"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for episode in range(num_episodes):\n",
    "    print(\"Episode:\",episode)\n",
    "    state= env.reset()\n",
    "    state = format_frame(state)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    tko_timer = 0\n",
    "    game = []\n",
    "    \n",
    "    for step in range(game_length):\n",
    "        #env.render() #sadly we have to render this env\n",
    "        \n",
    "        action = select_action(exploration_rate,state,dqn)\n",
    "        \n",
    "        prev_state = state\n",
    "        \n",
    "        state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if(reward <= -.1):\n",
    "            tko_timer +=1\n",
    "            \n",
    "        else:\n",
    "            tko_timer = 0\n",
    "            \n",
    "        #remove the negative constant penalty\n",
    "        reward = int(10*reward + 1)\n",
    "        state = format_frame(state)\n",
    "        \n",
    "        experience= [prev_state,action,reward,state]\n",
    "        game.append(experience)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #replay_memory.add(experience)\n",
    "        \n",
    "        #tracking how far we are getting\n",
    "        episode_reward +=reward\n",
    "        \n",
    "        if(done or tko_timer >=100):\n",
    "            # if we haven't gotten a positive reward \n",
    "            # in the last 20 steps \n",
    "            # or the game is over: stop\n",
    "            if(step > 25):\n",
    "                [replay_memory.add(e) for e in game]\n",
    "            break\n",
    "        \n",
    "    \n",
    "    #end of episode variable unm pdating\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
    "    \n",
    "    rewards.append(episode_reward)\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    print(\"exploration_rate:\",exploration_rate)\n",
    "    \n",
    "    if(episode%training_episodes == 0 and episode != 0):\n",
    "        print(\"Training on Experience\")\n",
    "        dqn = learn_from_data(dqn,target,replay_memory.replay(),optimizer)\n",
    "    if(episode%target_episodes ==0):\n",
    "        print(\"updating the target network\")\n",
    "        target = update_target(dqn,target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
